<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>CSAPP-阅读笔记-6-存储器层次结构</title>
    <link href="/2024/08/27/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-6-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/"/>
    <url>/2024/08/27/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-6-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/</url>
    
    <content type="html"><![CDATA[<p>​**存储器系统(memory system)<strong>是一个具有不同容量、成本和访问时间的存储设备的层次结构。CPU寄存器保存着最常用的数据。靠近CPU的小的、快速的</strong>高速缓存存储器(cache memory)<strong>作为一部分存储在相对慢速的</strong>主存储器(main memory，简称主存)**中的数据和指令的缓冲区域。主存暂时存放存储在容量较大的、慢速磁盘上的数据，而这些磁盘常常又作为存储在通过网络连接的其他机器的磁盘或磁带上的数据的缓冲区域。</p><p>​这里就是计算机系统中一个基本而持久的思想:如果你理解了系统是如何将数据在存储器层次结构中上上下下移动的，那么你就可以编写你的应用程序，使得它们的数据项存储在层次结构中较高的地方，在那里CPU能更快地访问到它们。</p><p>​这个思想围绕着计算机程序的一个称为**局部性(locality)<strong>的基本属性。具有良好局部性的程序倾向于一次又一次地访问相同的数据项集合，或是倾向于访问邻近的数据项集合。具有良好局部性的程序比局部性差的程序更多地倾向于从存储器层次结构中较高层次处访问数据项，因此运行得更快。例如，不同的矩阵乘法核心程序执行相同数量的算术操作，但是有不同程度的局部性，它们的运行时间可以相差20倍!。我们向你展示如何分析C程序的局部性，而且我们还介绍改进你的程序中局部性的技术。你还会学到一种描绘某台机器上存储器层次结构的性能的有趣方法，称为</strong>“存储器山”(memory mountain)**，它给出的读访问时间是局部性的一个数。</p><p>执行指令时访问数据所需的周期数：</p><ol><li>CPU寄存器：0个周期</li><li>L1L3高速缓存：475个周期</li><li>主存：上百个周期</li><li>磁盘：几千万个周期</li></ol><h1 id="1-存储技术"><a href="#1-存储技术" class="headerlink" title="1.存储技术"></a>1.存储技术</h1><p><strong>几种基本的存储技术</strong></p><ol><li><strong>随机访问存储器</strong>，分为两类：</li><li><ol><li><strong>RAM</strong>，同时也是<strong>易失性存储器</strong>，也分为两类：</li><li><ol><li><strong>SRAM</strong>：静态随机访问存储器，速度快，价格高。多用来作为高速缓存存储器。</li><li><strong>DRAM</strong>：动态随机访问存储器，速度慢，价格低。多用来作为主存和图形系统的帧缓冲器</li></ol></li><li><strong>ROM</strong>，同时也是<strong>非易失性存储器</strong>。<strong>闪存</strong>属于 ROM，<strong>固态硬盘</strong>就是基于闪存开发而来。</li></ol></li><li>机械硬盘</li><li>固态硬盘（SSD）</li></ol><h2 id="1-1-随机访问存储器"><a href="#1-1-随机访问存储器" class="headerlink" title="1.1 随机访问存储器"></a>1.1 随机访问存储器</h2><p>​随机访问存储器(Random-Access Memory，RAM)分为两类:静态的和动态的。静态RAM(SRAM)比动态RAM(DRAM)更快，但也贵得多。SRAM用来作为高速缓存存储器，既可以在CPU芯片上，也可以在片下。DRAM用来作为主存以及图形系统的帧缓冲区。典型地，一个桌面系统的SRAM不会超过几兆字节，但是DRAM却有几百或几千兆字节。</p><h3 id="1-静态-RAM（SRAM）"><a href="#1-静态-RAM（SRAM）" class="headerlink" title="1.静态 RAM（SRAM）"></a>1.静态 RAM（SRAM）</h3><p>SRAM 将每个位存储在一个双稳态的存储器单元内。每个单元由六个晶体管组成。</p><p>双稳态即该电路无限期地稳定保持在两个不同的电压状态。</p><p>对于 SRAM，只要有电，就永远地保持它的值。即使有干扰，当干扰消除，电路也会恢复到稳定</p><h3 id="2-动态-RAM（DRAM）"><a href="#2-动态-RAM（DRAM）" class="headerlink" title="2.动态 RAM（DRAM）"></a>2.动态 RAM（<strong>DRAM</strong>）</h3><p>DRAM 将每个位存储为对一个电容的充电。每个 DRAM 单元由一个电容和一个访问晶体管组成。</p><p>DRAM 对干扰非常敏感。当电容的电压被扰乱后，就永远不会恢复了</p><h3 id="3-SRAM和DRAM的区别"><a href="#3-SRAM和DRAM的区别" class="headerlink" title="3.SRAM和DRAM的区别"></a><strong>3.SRAM和DRAM的区别</strong></h3><p>只要有电源，SRAM是持续的。与DRAM不同，不需要刷新。SRAM的存取比DRAM快。SRAM对诸如光和电噪声之类的干扰不敏感。其代价是SRAM电池比DRAM电池使用更多的晶体管，因此密度更低，价格更贵，消耗更多电力。</p><p><img src="/2024/08/27/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-6-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/f0bdbfd58ae7b34da811ae7aac5560ef.png"></p><h3 id="4-传统的DRAM"><a href="#4-传统的DRAM" class="headerlink" title="4.传统的DRAM"></a>4.传统的DRAM</h3><p>​DRAM芯片中的单元(位)被分成d个*<em>超单元(supercell)*<em>，每个超单元都由w个DRAM单元组成，w 一般为 8。一个</em>dw*的 DRAM 总共存储了</em>dw*位信息。当从 DRAM 中读取数据时，一次可以读取一个超单元的数据（可以近似的将超单元理解为一个字节）。信息通过称为**引脚(pin)**的外部连接器流入和流出芯片。每个引脚携带一个1位的信号。</p><p>DRAM 中的超单元按行列组织，DRAM 中还包含一个行缓冲区。</p><p><strong>内存控制器</strong> <strong>依次</strong> 将行地址和列地址发送给 DRAM，DRAM 将对应的超单元的内容发回给内存控制器以实现读取数据。行地址和列地址共享相同的 DRAM 芯片地址引脚<br><img src="/2024/08/27/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-6-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/q4HjUwednvJBWAK.png"></p><p><strong>从 DRAM 中读取超单元的步骤：</strong></p><ol><li>内存控制器发来行地址 i，DRAM 将整个第 i 行复制到内部的行缓冲区。称为<strong>RAS(Row Access Strobe，行访问选通脉冲)请求</strong>。</li><li>内存控制器发来列地址 j，DRAM 从行缓冲区中复制出超单元 (i,j) 并发送给内存控制器。<strong>称为CAS(Column<br>Access Strobe，列访问选通脉冲)请求</strong>。</li></ol><ul><li>注意：RAS和CAS请求共享相同的 DRAM 地址引脚。</li></ul><p><img src="/2024/08/27/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-6-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/byWis1uH8FIBPkR.png"></p><h3 id="5-内存模块"><a href="#5-内存模块" class="headerlink" title="5.内存模块"></a>5.内存模块</h3><p>​许多 DRAM 芯片封装在<strong>内存模块</strong>中，插到主板的扩展槽上。常用的是<strong>双列直插内存模块 (DIMM)，以 64 位为块与内存控制器交换数据</strong>。</p><p>​比如一个内存模块包含 8 个 DRAM 芯片，每个 DRAM 包含 8M 个超单元，每个超单元存储一个字节（8bit）。<strong>使用 8 个 DRAM 芯片上相同地址处的超单元来表示一个 64 位字</strong>，DRAM 0 存储第一个字节，DRAM 1 存储第 2 个字节，依此类推。</p><p>​要取出内存地址 A 处的一个字，内存控制器先将 A 转换为一个超单元地址 (i,j)，然后内存模块将 i,j 广播到每个 DRAM。作为响应，每个 DRAM 输出它的 (i,j) 超单元的 8 位内容，合并成一个 64 位字，再返回给内存控制器。</p><p><strong>主存由多个内存模块连接到内存控制器聚合成。</strong></p><p><img src="/2024/08/27/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-6-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/iGR7WzclrCwB1Dv.png"></p><p>接下来，设r表示一个DRAM阵列中的行数，c表示列数，b.r表示行寻址所需的位数,b.c表示列寻址所需的位数。对于下面每个DRAM，确定2的幂数的阵列维数，使得max(b.r，b.c)最小，max(b.r，b.c)是对阵列的行或列寻址所需的位数中较大的值。</p><p><img src="/2024/08/27/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-6-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/4AKBRfjX6mgVU2H.png"></p><h3 id="6-增强的DRAM"><a href="#6-增强的DRAM" class="headerlink" title="6.增强的DRAM"></a>6.增强的DRAM</h3><p>有一些经过优化的 DRAM：</p><ol><li>**快页模式 DRAM (FPM DRAM)**：当连续访问位于同一行的超单元时，第二次以后，FPM DRAM 可以直接从行缓冲区获取数据。</li><li>**扩展数据输出 DRAM (EDO DRAM)**：FPM DRAM 的一个增强的形式，更快一些。</li><li>*<em>同步 DRAM (*</em>**SDRAM****)**：常规的、FPM 和 EDO 都是异步的。从效果而言，SDRAM 可以比异步存储器更快地输出它的超单元的内容。</li><li>**双倍数据速率同步 DRAM(DDR SDRAM)**：对 SDRAM 的一种增强，使速度翻倍。不同的 DDR SDRAM 以提高有效带宽的很小的预留缓冲区的大小来划分：DDR(2位)、DDR2(4位)、DDR3(8位)。位越多速度越快，近乎翻倍。</li><li>**视频 RAM (VRAM)**：用在图形系统的帧缓冲区中，其思想与 FPM DRAM 类似。VRAM 允许对内存进行并行地读和写。因此系统可以在写下一次更新的新值时（写），用帧缓冲区的像素刷屏幕（读）。</li></ol><h3 id="7-非易失性存储器"><a href="#7-非易失性存储器" class="headerlink" title="7.非易失性存储器"></a><strong>7.非易失性存储器</strong></h3><p>​DRAM 和 SRAM 会在断电后丢失信息，因此是易失性存储器。<strong>ROM</strong> 是非易失性存储器，在断电后仍保存着信息。</p><p>ROM 是只读存储器，但是实际上有些 ROM 既可以读也可以写。</p><p><strong>几种常见的非易失性存储器：</strong></p><ol><li>**可编程 ROM (PROM)**：只能被编程一次。</li><li>**可擦写可编程 ROM (EPROM)**：可以被擦除和重编程上千次。</li><li>**电子可擦除 PROM (EEPROM)**：类似于 EPROM，但是可以被重编程十万次。</li><li><strong>闪存</strong>：基于 EEPROM 的一种存储技术。闪存无处不在，<strong>固态硬盘就是一种基于闪存的磁盘驱动器</strong>。</li></ol><p>存储在 ROM 设备中的程序通常称为**固件(frmware)**。当一个计算机系统通电以后，它会运行存储在 ROM 中的固件。一些系统在固件中提供了少量基本的输入和输出函数–例如，PC的 **BIOS(基本输人&#x2F;输出系统)**例程。复杂的设备，像图形卡和磁盘驱动控制器，也依赖固件翻译来自CPU的IO(输入&#x2F;输出)请求。</p><h3 id="8-访问主存"><a href="#8-访问主存" class="headerlink" title="8.访问主存"></a>8.访问主存</h3><p>​数据流通过称为**总线(bus)<strong>的共享电子电路在处理器和DRAM主存之间来来回回。每次 CPU和主存之间的数据传送都是通过一系列步骤来完成的，这些步骤称为</strong>总线事务(bustransaction)**。</p><ul><li><p>**读事务(read transaction)**从主存传送数据到CPU。</p></li><li><p>**写事务(write transaction)**从CPU 传送数据到主存。</p></li></ul><p>总线是一组并行的导线，能携带地址、数据和控制信号。</p><p><strong>系统总线</strong>连接 CPU 和 IO 桥接器，<strong>内存总线</strong>连接 IO 桥接器和主存。IO 桥同时也连接着 <strong>I&#x2F;O 总线</strong>。</p><p><img src="/2024/08/27/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-6-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/a3dcf3bc826d53044f98037023c53acb.png"></p><p><strong>读事务</strong>的三个步骤：</p><ol><li>CPU 将地址 A 放到内存总线上。</li><li>主存从总线读出 A，取出字 x，然后将 x 放到总线上。</li><li>CPU 从总线读出字 x，并将它复制到相应寄存器中</li></ol><p><img src="/2024/08/27/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-6-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/339f2d400708f6d104959422ba43df8b.png"></p><p><strong>写事务</strong>的三个步骤：</p><ol><li>CPU 将地址 A 放到内存总线。主存读出这个地址，并等待数据字。</li><li>CPU 将数据字 y 放到总线上。</li><li>主存从总线读数据字 y，并将它存储在地址 A。</li></ol><p><img src="/2024/08/27/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-6-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/3ac92a496f20898fcec5902f146c054c.png"></p><h2 id="1-2-磁盘存储"><a href="#1-2-磁盘存储" class="headerlink" title="1.2 磁盘存储"></a>1.2 磁盘存储</h2><h3 id="1-磁盘构造"><a href="#1-磁盘构造" class="headerlink" title="1. 磁盘构造"></a><strong>1. 磁盘构造</strong></h3><p>略</p><h3 id="2-磁盘容量"><a href="#2-磁盘容量" class="headerlink" title="2. 磁盘容量"></a><strong>2. 磁盘容量</strong></h3><p>略</p><h3 id="3-磁盘操作"><a href="#3-磁盘操作" class="headerlink" title="3. 磁盘操作"></a><strong>3. 磁盘操作</strong></h3><p>略</p><h3 id="4-逻辑磁盘块"><a href="#4-逻辑磁盘块" class="headerlink" title="4.逻辑磁盘块"></a>4.<strong>逻辑磁盘块</strong></h3><p>略</p><h3 id="5-连接I-O设备"><a href="#5-连接I-O设备" class="headerlink" title="5. 连接I&#x2F;O设备"></a>5. 连接I&#x2F;O设备</h3><p>系统总线与内存总线都是与 CPU 相关的，而 IO 总线与 CPU 无关。</p><p>Intel 的<strong>外部设备互连总线（PCI）</strong>就是一种 IO 总线（广播总线）。</p><p>IO 总线速度相比于系统总线和内存总线慢，但是可以容纳种类繁多的第三方 IO 设备。</p><p>连接到 IO 总线的<strong>三种设备</strong>：</p><ol><li><strong>通用串行总线（USB）</strong>：USB 总线是一个广泛使用的<strong>标准</strong>，连接各种 IO 设备，包括键盘、鼠标等。</li><li><strong>显卡&#x2F;显示适配器：</strong>负责代表 CPU 在显示器上画像素。</li><li><strong>主机总线适配器：</strong>连接磁盘。常总的磁盘接口是 <strong>SCSI 和 SATA</strong>。其中 SCSI 比 SATA 更快也更贵。</li></ol><p><img src="/2024/08/27/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-6-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/200afce0c40dc9a454550bfbddf9a422.png"></p><h3 id="6-访问磁盘"><a href="#6-访问磁盘" class="headerlink" title="6.访问磁盘"></a><strong>6.访问磁盘</strong></h3><p>​CPU 使用**内存映射 I&#x2F;O (memory-mapped I&#x2F;O)**来向 I&#x2F;O 设备发射命令。在使用内存映射 IO 的系统中，地址空间中有一块地址是专为与 IO 设备通信保留的，每个这样的地址称为一个 IO 端口。当一个设备连接到总线时，它与一个或多个端口相关联。</p><p>假设磁盘控制器映射到端口 0xa0，<strong>读一个磁盘扇区的步骤如下：</strong></p><ol><li>CPU 依次发送命令字、逻辑块号、目的内存地址三条指令到 地址 0xa0，发起一个磁盘读。因为磁盘读的时间很长，所以此后 CPU 会转去执行其他工作。</li></ol><p><img src="/2024/08/27/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-6-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/4ed158cbd6bc3b547461648ceb26ecb1.png"></p><ol start="2"><li>磁盘收到读命令后，将逻辑块号翻译成一个扇区地址，读取该扇区的内容，并将内容直接传送到主存，不需要经过 CPU (这称为直接内存访问(DMA))。</li></ol><p><img src="/2024/08/27/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-6-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/488d9c3f16fa663d4c66dea5efee22ff.png"></p><ol start="3"><li>DMA 传送完成后，即磁盘扇区的内容安全地存储在主存中后，磁盘控制器给 CPU 发送一个中断信号(Interrupt)来通知 CPU。</li></ol><p><img src="/2024/08/27/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-6-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/80aaa6c0f95d1b6f78b66f070350437e.png"></p><h2 id="1-3-固态硬盘"><a href="#1-3-固态硬盘" class="headerlink" title="1.3 固态硬盘"></a>1.3 <strong>固态硬盘</strong></h2><p><strong>固态硬盘 (SSD)</strong> 是一种基于闪存的存储技术。</p><p>一个固态硬盘中封装了一个<strong>闪存翻译层</strong>和多个闪存芯片。闪存翻译层是一个硬件&#x2F;固件设备，功能类似磁盘控制器，将对逻辑块的请求翻译成对底层物理设备的访问。</p><p>一个闪存由 B 个块的序列组成，每个块由 P 页组成，页的大小为 512byte~4kb。数据以页为单位进行读写。</p><p><img src="/2024/08/27/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-6-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/458f772f9bb9c637418d692c7c532c57.png"></p><p>对于 SSD 来说，<strong>读比写快</strong>。因为只有在一页所属的块整个被擦除后，才能写这一页。重复写十万次后，块就会磨损，因此固态硬盘寿命较低。</p><p><strong>随机写 SSD 很慢的两个原因：</strong></p><ol><li>擦除块需要相对较长的时间。</li><li>如果写操作试图修改一个已经有数据的页，那么这个块中所有带有用数据的页都必须复制到一个新的块，然后才能向该页写数据。</li></ol><p><strong>SSD 相比于旋转磁盘的优点：</strong>由半导体存储器构成，没有移动部件，所以更结实，随机访问也更快，能耗更低。</p><p><strong>缺点</strong>：更容易磨损，不过现在的 SSD 已经可以用很多年了。</p><p>基于闪存（flash memory）的存储技术</p><h2 id="1-4-存储技术趋势"><a href="#1-4-存储技术趋势" class="headerlink" title="1.4 存储技术趋势"></a>1.4 存储技术趋势</h2><p><strong>性能上：</strong>SRAM &gt; DRAM &gt; SSD &gt; 旋转磁盘</p><p><strong>发展速度上</strong>：增加密度(降低成本) &gt; 降低访问时间</p><p>DRAM 和 磁盘的性能滞后于 CPU 的性能提升速度，两者之间的差距越来越大。</p><p><img src="/2024/08/27/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-6-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/7719fde4c6dafec46ee9c426c508f0a2.png"></p><h1 id="2-局部性"><a href="#2-局部性" class="headerlink" title="2.局部性"></a>2.局部性</h1><p>​实际上弥补CPU和内存之间差距的关键，是程序的局部性。一个编写良好的计算机程序常常具有良好的**局部性(locality)<strong>。也就是说，它们倾向于引用邻近于其他最近引用过的数据项的数据项，或者最近引用过的数据项本身。这种倾向性，被称为</strong>局部性原理(principle of locality)**，是一个持久的概念，对硬件和软件系统的设计和性能都有着极大的影响。</p><p>​局部性是程序的一个基本属性。具有良好局部性的程序倾向于**重复地访问相同的数据 (时间局部性 temporal locality)<strong>，或倾向于</strong>访问邻近的数据 (空间局部性 spatial locality)**，因此运行更快。</p><p><strong>局部性有两种形式</strong>：时间局部性和空间局部性。</p><p>现代计算机系统的各个层次，从硬件到操作系统到应用程序都利用了局部性。</p><h2 id="2-1-对程序数据引用的局部性"><a href="#2-1-对程序数据引用的局部性" class="headerlink" title="2.1 对程序数据引用的局部性"></a><strong>2.1 对程序数据引用的局部性</strong></h2><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs excel">for(<span class="hljs-built_in">int</span> i=<span class="hljs-number">0</span>; i&lt;<span class="hljs-built_in">N</span>; ++i) &#123;<br><span class="hljs-built_in">sum</span> += v[i];<br>&#125;<br></code></pre></td></tr></table></figure><p>上例中，sum 具有好的时间局部性，向量 v 具有好的空间局部性。</p><p>这里对向量 v 中元素的访问是顺序访问的，称为<strong>步长为 1 的引用模式</strong>。在空间局部性上，步长为 1 的引用模式是最好的。</p><h2 id="2-2-取指令的局部性"><a href="#2-2-取指令的局部性" class="headerlink" title="2.2 取指令的局部性"></a><strong>2.2 取指令的局部性</strong></h2><p>​程序指令存放在内存中，CPU 需要读这些指令，因此取指令也有局部性。比如 for 循环中的指令具有好的时间局部性和空间局部性。</p><h2 id="2-3-局部性小结"><a href="#2-3-局部性小结" class="headerlink" title="2.3 局部性小结"></a><strong>2.3 局部性小结</strong></h2><p><strong>评价局部性的简单原则：</strong></p><ol><li>重复引用相同变量的程序有好的时间局部性。</li><li>对于步长为 k 的引用模式的程序，k 越小，空间局部性越好。</li><li>对于取指令来说，循环有好的时间和空间局部性。循环体越小，循环迭代次数越多，局部性越好。</li></ol><h1 id="3-存储器层次结构"><a href="#3-存储器层次结构" class="headerlink" title="3.存储器层次结构"></a>3.存储器层次结构</h1><p><img src="/2024/08/27/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-6-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/9a5f7056a064b85cd13ef10cd7b59960.png"></p><h2 id="3-1-在存储器层次结构中的缓存"><a href="#3-1-在存储器层次结构中的缓存" class="headerlink" title="3.1 在存储器层次结构中的缓存"></a>3.1 在存储器层次结构中的缓存</h2><p>一般而言，高速缓存(cache)是一个小而快速的存储设备。使用高速缓存的过程称为缓存(caching)。</p><p><strong>存储器层次结构的中心思想</strong>：对于每个 k，位于 k 层的更快更小的存储设备作为位于 k+1 层的更大更慢的存储设备的缓存。换句话说，层次结构中的每一次都缓存来自较低一层的数据对象。</p><p><strong>缓存的具体实现：</strong>数据总是以**块(block)**大小为传送单元(transfer unit)在第 k 层和第 k+1 层之间来回拷贝的。虽然在层次结构中任何一对相邻的层次之间块大小是固定的，但是其他的层次对之间可以用不同的块大小。</p><p>一般而言，层次结构较低的层(离 CPU 较远)的设备访问时间较长，因此为了补偿这些较长的访问时间，倾向于使用较大的块</p><p><img src="/2024/08/27/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-6-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/968eef5426637935d231b7a7d020e33b.png"></p><p><strong>1. 缓存命中</strong></p><p>当需要 k+1 层的某个数据对象 d 时，如果 d 恰好缓存在 k 层中，就称为缓存命中</p><p><strong>2. 缓存不命中</strong></p><p>缓存不命中时，第 k 层的缓存从 第 k+1 层缓存中取出包含 d 的块。</p><p>如果第 k 层缓存已经满了，需要根据<strong>替换策略</strong>选择一个块进行覆盖 (替换)，未满的话需要根据放置策略来选择一个块放置。</p><p><strong>3. 缓存不命中的种类</strong></p><ol><li><strong>冷不命中</strong>：一个空的缓存称为<strong>冷缓存</strong>，冷缓存必然不命中，称为冷不命中。</li><li><strong>冲突不命中：</strong>常用的放置策略是将 k+1 层的某个块限制放置在 k 层块的一个小的子集中。比如 k+1 层的块 1,5,9,13 映射到 k 层的块 0。这会带来冲突不命中。</li><li><strong>容量不命中</strong>：当访问的工作集的大小超过缓存的大小时，会发生容量不命中。即缓存太小了，不能缓存整个工作集。</li></ol><p><strong>4. 缓存管理</strong></p><p>寄存器文件的缓存由编译器管理，L1,L2,L3 的缓存由内置在缓存中的硬件逻辑管理，DRAM 主存作为缓存由操作系统和 CPU 上的地址翻译硬件共同管理。</p><p><img src="/2024/08/27/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-6-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/fe4b962f01599eefb4a138a7d24ad91f.png"></p><h2 id="3-2-存储器层次结构概念小结"><a href="#3-2-存储器层次结构概念小结" class="headerlink" title="3.2 存储器层次结构概念小结"></a>3.2 存储器层次结构概念小结</h2><p>存储器层次结构行之有效，因为较慢的设备比较快的设备更便宜，还因为程序偏向于展示局部性：</p><ul><li>利用时间局部性，同一数据对象可能会被多次使用</li><li>利用空间局部性，块通常包含有多个数据对象</li></ul><h1 id="4-高速缓存存储器"><a href="#4-高速缓存存储器" class="headerlink" title="4.高速缓存存储器"></a>4.高速缓存存储器</h1><p>L1 高速缓存的访问速度约为 4 个时钟周期，L2 约 10 个周期，L3 约 50 个周期。</p><p>当 CPU 执行一条读内存字 w 的指令，它首先向 L1 高速缓存请求这个字，如果 L1 没有就向 L2，依此而下。</p><h2 id="4-1-通用的高速缓存存储结构"><a href="#4-1-通用的高速缓存存储结构" class="headerlink" title="4.1 通用的高速缓存存储结构"></a>4.1 通用的高速缓存存储结构</h2><p>假设一个计算机系统中的存储器地址有 m 位，形成 M &#x3D;2^m 个不同的地址。m 个地址为划分为 <strong>t 个标记位</strong>，<strong>s 个组索引位</strong>，<strong>b 个块偏移位</strong>。</p><p>高速缓存被组织成 S&#x3D;2^s 个<strong>高速缓存组</strong>，每个组包含 E 个<strong>高速缓存行</strong>，<strong>每个行为一个数据块</strong>，包含一个<strong>有效位</strong>，t&#x3D;m-(b+s) 个<strong>标记位</strong>，和 B&#x3D;2^b 字节的<strong>数据块</strong>。高速缓存的容量 &#x3D; S * E * B。</p><p><strong>高速缓存可以通过简单地检查地址位来找到所请求的字。</strong></p><p>当 CPU 要从地址 A(由m个地址位组成) 处读一个字时：</p><ol><li>A 中的 s 个组索引位告诉我们在哪个组中</li><li>A 中的 t 个标记位告诉我们在这个组中的哪一行：当且仅当这一行设置了有效位并且标记位与 A 中的标记位匹配时，才说明这一行包含这个字。</li><li>A 中的 b 个块偏移位告诉我们在 B 个字节的数据块中的字偏移。</li></ol><p><img src="/2024/08/27/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-6-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/c8140e57b956abeabe18f8c94a2d68df.png"><br><img src="/2024/08/27/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-6-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/6bee7795fe8f9ea08c72151e3e46aece.png"></p><p><img src="/2024/08/27/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-6-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/B4KzO5S7sC8hNeg.png"></p><p><strong>理解</strong></p><p>使用高位做标记位，可以避免连续的块被映射到同一高速缓存组中。</p><p><strong>通过高速缓存从内存读字</strong></p><p>假设一个系统中只有 CPU、L1 高速缓存和主存。</p><p>当 CPU 执行一条从内存读字 w 的指令，如果 L1 有 w 的副本，就得到 L1 高速缓存命中；如果 L1 没有，就是缓存不命中。</p><p>当缓存不命中，L1 会向主存请求包含 w 的块(L1 中的块就是它的高速缓存行)的一个副本。当块从内存到达 L1，L1 将这个块存在它的一个高速缓存行里，然后从中抽取出字 w，并返回给 CPU。</p><p>高速缓存确定一个请求是否命中，然后抽取出被请求的字的过程分为三步:</p><ol><li><strong>组选择</strong></li><li><strong>行匹配</strong></li><li><strong>字抽取</strong></li></ol><p><img src="/2024/08/27/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-6-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/mUPZ8qux5VJODks.png"></p><p><strong>高速缓存有以下几类：</strong></p><ol><li><strong>直接映射高速缓存</strong>：每个组只有一行，即 E&#x3D;1。</li><li><strong>组相联高速缓存</strong>：每个组有多行，1</li><li><strong>全相联高速缓存</strong>：只有一个组，E&#x3D;C&#x2F;B。</li></ol><h2 id="4-2-直接映射高速缓存"><a href="#4-2-直接映射高速缓存" class="headerlink" title="4.2 直接映射高速缓存"></a>4.2 直接映射高速缓存</h2><p>每个组只有一行（E&#x3D;1）的高速缓存被称为直接映射高速缓存</p><h3 id="1-直接映射高速缓存中的组选择"><a href="#1-直接映射高速缓存中的组选择" class="headerlink" title="1. 直接映射高速缓存中的组选择"></a><strong>1. 直接映射高速缓存中的组选择</strong></h3><p>在这一步中，高速缓存从<strong>w的地址中间抽取出s个组索引位</strong>。这些位被解释成一个对应于个组号的无符号整数。换句话来说，如果我们把高速缓存看成是一个关于<strong>组的一维数组</strong>，那么这些组索引位就是一个到这个数组的索引。图6-30展示了直接映射高速缓存的组选择是如何工作的。在这个例子中，组索引位00001,被解释为一个选择组1的整数索引。</p><p><img src="/2024/08/27/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-6-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/0a1561d9733806ede8ffd1198bd7e4a1.png"></p><h3 id="2-直接映射高速缓存中的行匹配"><a href="#2-直接映射高速缓存中的行匹配" class="headerlink" title="2. 直接映射高速缓存中的行匹配"></a><strong>2. 直接映射高速缓存中的行匹配</strong></h3><p>因为直接映射高速缓存每个组只有一行，只要这一行设置了有效位且标记位相匹配，就说明想要的字的副本确实存储在这一行中。</p><h3 id="3-直接映射高速缓存中的字抽取"><a href="#3-直接映射高速缓存中的字抽取" class="headerlink" title="3. 直接映射高速缓存中的字抽取"></a><strong>3. 直接映射高速缓存中的字抽取</strong></h3><p>从 w 的地址中抽取出 b 个块偏移位，块偏移位提供了所需的字的第一个字节的偏移。</p><h3 id="4-直接映射高速缓存不命中时的行替换"><a href="#4-直接映射高速缓存不命中时的行替换" class="headerlink" title="4. 直接映射高速缓存不命中时的行替换"></a><strong>4. 直接映射高速缓存不命中时的行替换</strong></h3><p>缓存不命中时需要从下一层取出被请求的块，然后将其存储在组索引位指示的组中的高速缓存行中。</p><p>因为直接映射高速缓存每个组只有一行，所以替换策略很简单：用新取出的行替换当前行。</p><h3 id="5-运行中的直接映射高速缓存"><a href="#5-运行中的直接映射高速缓存" class="headerlink" title="5. 运行中的直接映射高速缓存"></a><strong>5. 运行中的直接映射高速缓存</strong></h3><p>标记位和索引位连接起来标识了整个内存中的所有块，而高速缓存中的高速缓存组（块）是少于内存中的块数的。因此位于不同标记位，相同组索引位的块会映射到高速缓存中的同一个高速缓存组。</p><p>在一个高速缓存组中存储了哪个块，可以由标记位唯一地标识。</p><p>理解：对于主存中的整个地址空间，根据标记位不同将其分为了若干个部分，每个部分可以单独且完整地映射到高速缓存中，且刚好占满整个直接映射高速缓存。</p><h3 id="6-直接映射高速缓存中的冲突不命中"><a href="#6-直接映射高速缓存中的冲突不命中" class="headerlink" title="6. 直接映射高速缓存中的冲突不命中"></a><strong>6. 直接映射高速缓存中的冲突不命中</strong></h3><p>冲突不命中在直接映射高速缓存中很常见。因为每个组只有一行，不同标记位的块会映射到同一行，发生冲突不命中。</p><h3 id="7-综合-运行中的直接映射高速缓存"><a href="#7-综合-运行中的直接映射高速缓存" class="headerlink" title="7.综合:运行中的直接映射高速缓存"></a>7.综合:运行中的直接映射高速缓存</h3><p>​高速缓存用来选择组和标识行的机制极其简单。必须要这样，因为硬件必须在几个纳秒的时间内完成这些工作。不过，用这种方式来处理位对我们人来说是很令人困惑的。一个具体的例子能帮助我们解释清楚这个过程。假设我们有一个直接映射高速缓存，描述如下:<br>​(S，E，B，m)&#x3D;(4，1，2，4)<br>​换句话说，高速缓存有四个组，每个组一行，每个块2个字节，而地址是4位的。我们还假设每个字都是单字节的。当然，这样一些假设完全是不现实的，但是它们能使示例保持简单。</p><p>当你初学高速缓存时，列举出整个地址空间并划分好位是很有帮助的，就像我们在图6-32<br>中对4位的示例所做的那样。关于这个列举出的空间，有一些有趣的事情值得注意:</p><ul><li><strong>标记位和索引位连起来唯一地标识了存储器中的每个块。</strong>例如，块0是由地址0和1组成的，块1是由地址2和3组成的，块2是由地址4和5组成的，依此类推。</li><li>因为有8个存储器块，但是只有4个高速缓存组，多个块映射到同一个高速缓存组<br>(即它们有相同的组索引)。例如，块0和4都映射到组0，块1和5都映射到组1<br>等等。</li><li>映射到同一个高速缓存组的块由标记位唯一地标识。例如，块0的标记位为0，而块4的<br>标记位为 1，块1的标记位为 0，而块5的标记位为1，以此类推。</li></ul><h2 id="4-3-组相联高速缓存"><a href="#4-3-组相联高速缓存" class="headerlink" title="4.3 组相联高速缓存"></a>4.3 组相联高速缓存</h2><p>​直接映射高速缓存中冲突不命中造成的问题是源于每一个组只有一行，组相联高速缓存（set associative cache）放松了这条限制，所以每个组都保存了有多于一行的高速缓存</p><p><img src="/2024/08/27/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-6-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/195812beb411de0249eadb687b64ebb7.png"></p><h3 id="1-组相联高速缓存中的组选择"><a href="#1-组相联高速缓存中的组选择" class="headerlink" title="1. 组相联高速缓存中的组选择"></a><strong>1. 组相联高速缓存中的组选择</strong></h3><p>与直接映射高速缓存一样，组索引位标识组。</p><p><img src="/2024/08/27/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-6-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/d645d63a307ce00384cfdd794fd18e96.png"></p><h3 id="2-组相联高速缓存中的行匹配"><a href="#2-组相联高速缓存中的行匹配" class="headerlink" title="2. 组相联高速缓存中的行匹配"></a><strong>2. 组相联高速缓存中的行匹配</strong></h3><p>组相联高速缓存中的行匹配更复杂，因为要<strong>检查多个行的标记位和有效位</strong>，以确定其中是否有所请求的字。</p><p>注意：组中的任意一行都可能包含映射到这个组的内存块，因此<strong>必须搜索组中的每一行</strong>，寻找一个<strong>有效</strong>且<strong>标记位</strong>相匹配的行。</p><h3 id="3-组相联高速缓存中的字抽取"><a href="#3-组相联高速缓存中的字抽取" class="headerlink" title="3. 组相联高速缓存中的字抽取"></a><strong>3. 组相联高速缓存中的字抽取</strong></h3><p>与直接映射高速缓存一样，块偏移位标识所请求的字的第一个字节。</p><p><img src="/2024/08/27/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-6-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/5f816eb8b4fb94ceae68b929622752bd.png"></p><h3 id="4-组相联高速缓存中不命中时的行替换"><a href="#4-组相联高速缓存中不命中时的行替换" class="headerlink" title="4. 组相联高速缓存中不命中时的行替换"></a><strong>4. 组相联高速缓存中不命中时的行替换</strong></h3><p><strong>几种替换策略</strong></p><ol><li><strong>随机替换策略：</strong>随机选择要替换的行</li><li><strong>最不常使用策略：</strong>替换在过去某个时间窗口内引用次数最少的一行。</li><li><strong>最近最少使用策略：</strong>替换最后一次访问时间最久远的那一行。</li></ol><p>因为存储器层次结构中越靠下，不命中开销越大，好的替换策略越重要。</p><h2 id="4-4-全相联高速缓存"><a href="#4-4-全相联高速缓存" class="headerlink" title="4.4 全相联高速缓存"></a>4.4 全相联高速缓存</h2><p>全相联高速缓存由一个包含所有高速缓存行 (E&#x3D;C&#x2F;B) 的组组成。</p><p>因为高速缓存电路必须并行地搜索不同组已找到相匹配的标记，所以全相联高速缓存只适合做小的高速缓存。</p><p>DRAM 主存采用了全相联高速缓存，但是因为它采用了虚拟内存系统，所以在进行类似行匹配的页查找时不需要对一个个页进行遍历。</p><p><img src="/2024/08/27/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-6-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/5db3034bf836fa8a8811fdc7c33a4c1f.png"></p><h3 id="1-全相联高速缓存中的组选择"><a href="#1-全相联高速缓存中的组选择" class="headerlink" title="1. 全相联高速缓存中的组选择"></a><strong>1. 全相联高速缓存中的组选择</strong></h3><p>全相联高速缓存中只有一个组，所以地址中没有组索引位，只有标记位和块偏移位。</p><p><img src="/2024/08/27/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-6-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/310594023e2966d1704b4d3e079f5fd6.png"></p><h3 id="2-全相联高速缓存中的行匹配和字抽取"><a href="#2-全相联高速缓存中的行匹配和字抽取" class="headerlink" title="2. 全相联高速缓存中的行匹配和字抽取"></a><strong>2. 全相联高速缓存中的行匹配和字抽取</strong></h3><p>与组相联高速缓存一样。与组相联高速缓存的区别在于规模大小</p><p><img src="/2024/08/27/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-6-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/bb212df182d4beaec000f0e0781f37e0.png"></p><h2 id="4-5-有关写的问题"><a href="#4-5-有关写的问题" class="headerlink" title="4.5 有关写的问题"></a>4.5 有关写的问题</h2><p>写相比读要复杂一些。</p><p>写命中（写一个已经缓存了的字 w）的情况下，高速缓存更新了本层的 w 的副本后，如何处理低一层的副本有两种方法：</p><ol><li><strong>直写</strong>：立即将 w 的高速缓存块写回到低一层中。<ul><li>优点：简单</li><li>缺点：每次写都会占据总线流量</li></ul></li><li><strong>写回</strong>：尽可能地推迟更新，只有当替换算法要驱逐这个更新过的块时，才把它写到低一层中。<ul><li><strong>优点：利用了局部性，可以显著地减少总线流量。</strong></li><li>缺点：增加了复杂性。必须为每个高速缓存行维护一个额外的修改位，表明此行是否被修改过</li></ul></li></ol><p><strong>写不命中</strong>情况下的两种方法：</p><ol><li><p><strong>写分配</strong>：加载相应的低一层的块到本层中，然后更新这个高速缓存块。</p><ul><li><p>优点：利用写的空间局部性</p></li><li><p>缺点：每次不命中都会导致一个块从低一层传送到高速缓存</p></li></ul></li><li><p><strong>非写分配</strong>：避开高速缓存，直接把这个字写到低一层中</p></li></ol><p>直写一般与非写分配搭配，两者都更适用于存储器层次结构中的较高层。</p><p><strong>写回一般与写分配搭配，两者都更适用于存储器层次结构中的较低层，因为较低层的传送时间太长。</strong></p><p>因为硬件上复杂电路的实现越来越容易，所以现在使用写回和写分配越来越多。</p><h2 id="4-6-指令高速缓存和统一高速缓存"><a href="#4-6-指令高速缓存和统一高速缓存" class="headerlink" title="4.6 指令高速缓存和统一高速缓存"></a>4.6 指令高速缓存和统一高速缓存</h2><p><strong>三种高速缓存：</strong></p><ol><li><strong>i-cache：</strong>只保存指令的高速缓存。i-cache 通常是只读的，因此比较简单。</li><li><strong>d-cache：</strong>只保存程序数据的高速缓存。</li><li><strong>统一的高速缓存：</strong>既保存指令又保存程序数据.</li></ol><p>现代处理器一般包括独立的 i-cache 和 d-cache，其中两个原因如下：</p><ol><li>使用两个独立的高速缓存，CPU 可以同时读一个指令字和一个数据字。</li><li>可以确保数据访问不会与指令访问形成冲突不命中（不过可能会使容量不命中增加）。</li></ol><h2 id="4-7-高速缓存参数的性能影响"><a href="#4-7-高速缓存参数的性能影响" class="headerlink" title="4.7 高速缓存参数的性能影响"></a>4.7 高速缓存参数的性能影响</h2><p><strong>高速缓存的性能指标</strong></p><ol><li><strong>命中率：</strong>命中的内存引用比率。</li><li><strong>命中时间</strong>：从高速缓存传送一个字到 CPU 的时间，包括组选择、行确认和字抽取的实践。</li><li><strong>不命中处罚：</strong>不命中产生的额外时间消耗。</li></ol><p><strong>几个影响因素</strong></p><ol><li>高速缓存大小：较大的高速缓存可以提高命中率，但是会运行得更慢，即增加命中时间。</li><li>块大小：较大的块更能利用空间局部性以提高命中率。但是对于给定的总容量，块越大高速缓存行就越少，不利用利用时间局部性。较大的块因为传送时间更长，所以也会增加不命中处罚。现代处理系统的高速缓存块一般为 64 字节。</li><li>相联度：参数E的选择的影响（每个组中高速缓存行数）。E越高优点是：降低了高速缓存由于冲突不命中出现抖动的可能性。缺点：实现起来昂贵；增加命中时间；增加不命中处罚。</li><li>写策略：高速缓存越往下层，越可能使用写会而不是直写策略。</li></ol><h1 id="5-编写高速缓存友好的代码"><a href="#5-编写高速缓存友好的代码" class="headerlink" title="5.编写高速缓存友好的代码"></a>5.编写高速缓存友好的代码</h1><ol><li>让最常见的情况运行得快</li><li>在每个循环内部使缓存不命中数量小</li></ol><h1 id="6-综合：高速缓存对程序性能的影响"><a href="#6-综合：高速缓存对程序性能的影响" class="headerlink" title="6.综合：高速缓存对程序性能的影响"></a>6.综合：高速缓存对程序性能的影响</h1><p><strong>存储器山（memory mountain)</strong></p><p><img src="/2024/08/27/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-6-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/2018_1_28_1517112396218.jpg"></p><h1 id="6-7-小结"><a href="#6-7-小结" class="headerlink" title="6.7 小结"></a>6.7 小结</h1><p>程序员可以通过编写有良好空间和时间局部性的程序来显著地改进程序的运行时间。利用基于 SRAM 的高速缓存存储器特别重要。</p>]]></content>
    
    
    <categories>
      
      <category>CSAPP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CSAPP</tag>
      
      <tag>阅读笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CSAPP_阅读笔记_5_优化</title>
    <link href="/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/"/>
    <url>/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<div class="note note-secondary">            <p>Don’t design bridges in ignorance of materials, and don’t design low-level software in ignorance of the underlying hardware. </p>          </div><p>​写程序最主要的目标就是使它在所有可能的情况下都正确工作.一个运行得很快但是给出错误结果的程序没有任何用处.程序员必须写出清晰简洁的代码，这样做不仅是为了程序员能够看懂代码，也是为了在检查代码和今后需要修改代码时，其他人能够读和理解代码.</p><p>编写高效程序一般需要以下理解几类活动：</p><ul><li>选择合适的算法和数据结构</li><li>编写出编译器能够有效优化以转换程高效可执行代码的源代码。（需要我们理解优化编译器的能力和局限性）</li><li>对于大型任务，将一个任务分成多份，这些部分可以在多核和多处理器的某种组合上并行地进行计算。（利用并行性）</li></ul><p>本章主要介绍第二项。具体而言:</p><ul><li>消除不必要的工作，例如: 不必要的函数调用、<strong>内存引用</strong>、条件测试。这些工作通常不依赖于执行环境的操作，有些也可以被编译器优化。</li><li>利用处理器提供的指令级并行能力，同时执行多条指令。</li><li>使用profiler，确定程序中的关键路径并加以优化</li></ul><h1 id="1-优化编译器的能力和局限性"><a href="#1-优化编译器的能力和局限性" class="headerlink" title="1.优化编译器的能力和局限性"></a>1.优化编译器的能力和局限性</h1><div class="note note-secondary">            <p>gcc -O3 -o output_filename source_file.c</p>          </div><hr><p>编译器的优化行为需要满足一条基本的约束: “优化后的代码的行为和优化前的代码的行为相同”。</p><ul><li>大多数编译器分析局限在单个函数内<ul><li>基于整个程序的分析开销过于昂贵</li><li>新的GCC能够进行单个文件内部的过程间的分析</li></ul></li><li>大多数分析基于静态信息</li></ul><p>​编译器必须很小心地对程序只使用安全的优化，也就是说对于程序可能遇到的所有可能的情况，在C语言标准提供的保证之下，优化后得到的程序和未优化的版本有一样的行为。限制编译器只进行安全的优化，消除了一些造成不希望的运行时行为的可能原因，但是这也意味着程序员必须花费更大的力气写出程序使编译器能够将之转换成有效机器代码。为了理解决定一种程序转换是否安全的难度，让我们来看看下面这两个过程:</p><p>​<img src="/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/5-1.png"><br>​</p><p>​乍一看，这两个过程似乎有相同的行为。它们都是将存储在由指针yp指示的位置处的值两次加到指针 xp指示的位置处的值。另一方面，函数twiddle2效率更高一些。它只要求3次存储器引用(读<em>xp，读</em>yp，写<em>xp)，而twiddle1需要6次(2次读</em>xp，2次读<em>yp，2次写</em>xp)。因此，如果要编译器编译过程 twiddle1，我们会认为基于 twiddle2 执行的计算能产生更有效的代码。</p><p>不过，考虑 xp 等于 yp 的情况。此时，函数twiddle1 会执行下面的计算:<br>*Xp +&#x3D; <em>XP;<br>&#x2F;</em>[)puble value at xp *&#x2F;<br>*Xp +&#x3D; *XP;<br>&#x2F;*Double value at xp *&#x2F;<br>结果是 xp的值会增加4倍。另一方面，函数 twiddle2 会执行下面的计算:<br><em>xp+&#x3D;2**xp;&#x2F;</em> Triple value at xp *&#x2F;<br>结果是 xp的值会增加3倍。</p><p>​编译器不知道twiddle1会如何被调用，因此它必须假设参数 xp和 yp 可能会相等。因此，它不能产生 twiddle2 风格的代码作为 twiddle1的优化版本。这种两个指针可能指向同一个存储器位置的情况称为 **存储器别名使用(memory aliasing) **。在只执行安全的优化中，编译器必须假设不同的指针可能会指向存储器中同一个位置。</p><p><strong>解决</strong></p><ul><li>在内循环中使用本地变量进行accumulate以消除aliasing</li><li>通过声明为<code>double *restrict a</code>，告知编译器指针参数无法重叠</li></ul><hr><p>​第二个妨碍优化的因素是函数调用。作为一个示例，考虑下面这两个过程：</p><p><img src="/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/5-2-2.png"></p><p>最初看上去两个过程计算的都是相同的结果，但是func2只调用f1次，而func1调用f4次。以func1作为源时，会很想产生func2风格的代码。不过，考虑一下代码：</p><p>​<img src="/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/e64c886d1ac1301ff44d50b03f32c702.png"></p><p>这个函数有个副作用—它修改了全局程序状态的一部分。改变调用它的次数会改变程序的行为。特别地，假设开始时全局变量counter都设置为0，对func1的调用会返回0+1+2+3&#x3D;6，而对func2的调用会返回4·0-0。大多数编译器不会试图判断一个函数是否没有副作用，因此任意函数都可能是优化的候选者，例如 func2中的做法。相反，编译器会假设最糟的情况，并保持所有的函数调用不变。</p><p><strong>解决</strong></p><ul><li>使用内联函数</li><li>编程者自己进行代码移动(code motion)</li></ul><hr><h1 id="2-表示程序性能参数-Cycles-per-Element-CPE"><a href="#2-表示程序性能参数-Cycles-per-Element-CPE" class="headerlink" title="2.表示程序性能参数: Cycles per Element, CPE"></a>2.表示程序性能参数: Cycles per Element, CPE</h1><p>​我们引人度量标准**每元素的周期数(CyclesPerElement，CPE)**，作为一种表示程序性能并指导我们改进代码的方法。CPE这种度量标准帮助我们在更详细的级别上理解迭代程序的循环性能。这样的度量标准对执行重复计算的程序来说是很适当的，例如处理图像中的像素，或是计算矩阵乘积中的元素。</p><p>​<strong>CPE</strong>: <strong>计算&#x2F;处理单个元素所需要的时钟周期，CPE值越小越好</strong>。当过程在一组元素上迭代时，该过程执行的时钟周期数和被处理的元素个数能够用一个线性函数来描述，这个线性函数的斜率就是CPE。</p><p>​以下通过最小2乘估计所得到的线性函数，如图所示：</p><p><img src="/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/5-2.png"></p><h1 id="3-基础优化"><a href="#3-基础优化" class="headerlink" title="3.基础优化"></a>3.基础优化</h1><p>我们对以下函数进行分析：</p><p><img src="/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/fac86485822c416f2e817bd923adb0b8.png"></p><p>这些是初始的CPE：<br><img src="/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/b53c6237d9908d60d15b8a371f763134.png"></p><h2 id="3-1代码移动"><a href="#3-1代码移动" class="headerlink" title="3.1代码移动"></a>3.1代码移动</h2><ul><li>code motion: 避免执行多次但是计算结果不变的操作，改用局部变量保存计算结果。</li><li>注意: 某些code motion优化是编译器能够发现的。</li></ul><p>具体而言，在循环判断语句中要避免每次都重复计算数组长度（消除循环的低效率）</p><p>​<img src="/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/27197b6ea0d639415ced3655d8df2b17.png"><br>我们可以改成这样，接下来的CPE如图所示：</p><p><img src="/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/5-5.png"></p><p>这个优化是一类常见的优化的一个例子，称为代码移动(code motion)。这类优化包括识别要执行多次(例如在循环里)但是计算结果不会改变的计算。因而可以将计算移动到代码前面不会被多次求值的部分。在本例中，我们将对veclength的调用从循环内部移动到循环的前面。<br>优化编译器会试着进行代码移动。不幸的是，就像前面讨论过的那样，对于会改变在哪里调用函数或调用多少次的变换，编译器通常会非常小心。它们不能可靠地发现一个函数是否会有副<br>作用，因而假设函数会有副作用。例如，如果veclength有某种副作用，那么combine1和combine2可能就会有不同的行为。为了改进代码，程序员必须经常帮助编译器显式地完成代码的移动。</p><h2 id="3-2减少过程调用"><a href="#3-2减少过程调用" class="headerlink" title="3.2减少过程调用"></a>3.2减少过程调用</h2><p>注意到循环体内每次获取向量元素都要调用get_vex_element函数，考虑打破抽象，直接通过数组指针遍历：</p><p><img src="/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/b99719a50a081c6a41f7c1065d3b9d98.png"></p><p>然而结果性能没有显著增加，整数加法反而有所减小</p><p><img src="/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/cbdbefe26e79e7c381ca77aa09959342.png"></p><p>这说明过程调用的开销并非性能瓶颈。</p><h2 id="3-3消除不必要的内存引用"><a href="#3-3消除不必要的内存引用" class="headerlink" title="3.3消除不必要的内存引用"></a>3.3消除不必要的内存引用</h2><p><img src="/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/5f8a09af7ce887442c14120767bde793.png"></p><p>通过分析上述汇编代码注意到循环体内每次从dest处读取值，同时也要写入dest处。考虑使用局部变量保存中间结果能够简化为:</p><p><img src="/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/ad21d529498631fa5e96635ea820ce07.png"></p><p>对应的c代码为：</p><p><img src="/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/e0546036f2ddb6f5d80187327a54987c.png"></p><p>时间拥有显著的提升，如下：<br><img src="/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/5-9.png"></p><h2 id="3-4其他优化"><a href="#3-4其他优化" class="headerlink" title="3.4其他优化"></a>3.4其他优化</h2><h3 id="3-4-1-reduction-in-strength"><a href="#3-4-1-reduction-in-strength" class="headerlink" title="3.4.1. reduction in strength"></a>3.4.1. reduction in strength</h3><p>使用开销较小的操作替代开销较大的操作。</p><p>例如，使用x &lt;&lt; 4替代16 * x</p><ul><li>Intel Nehalem: 整数乘法操作需要消耗3个CPU时钟周期，加法操作需要消耗1个CPU时钟周期</li></ul><h3 id="3-4-2-share-common-subexpressions"><a href="#3-4-2-share-common-subexpressions" class="headerlink" title="3.4.2. share common subexpressions"></a>3.4.2. share common subexpressions</h3><p>重用部分表达式，避免重复计算。例如下面通过单个局部变量的计算，减少了3次冗余计算</p><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs excel">// version <span class="hljs-number">1</span><br>up = val[(i-<span class="hljs-number">1</span>)*<span class="hljs-built_in">n</span> + j];<br>down = val[(i+<span class="hljs-number">1</span>)*<span class="hljs-built_in">n</span> + j];<br><span class="hljs-built_in">left</span> = val[i*<span class="hljs-built_in">n</span> + j-<span class="hljs-number">1</span>];<br><span class="hljs-built_in">right</span> = val[i*<span class="hljs-built_in">n</span> + j+<span class="hljs-number">1</span>];<br>// version <span class="hljs-number">2</span><br>long inj = i*<span class="hljs-built_in">n</span> + j;<br>up = val [inj - <span class="hljs-built_in">n</span>];<br>down = val[inj + <span class="hljs-built_in">n</span>];<br><span class="hljs-built_in">left</span> = val[inj - <span class="hljs-number">1</span>];<br><span class="hljs-built_in">right</span> = val[inj + <span class="hljs-number">1</span>];<br></code></pre></td></tr></table></figure><ul><li>GCC的<strong>O1</strong>优化会优化这一点</li></ul><h1 id="4-理解现代处理器"><a href="#4-理解现代处理器" class="headerlink" title="4.理解现代处理器"></a>4.理解现代处理器</h1><p>​到目前为止，我们运用的优化都不依赖于目标机器的任何特性。这些优化只是简单地降低了过程调用的开销，以及消除了一些重大的“妨碍优化的因素”，这些因素会给优化编译器造成困难。随着试图进一步提高性能，我们必须考虑利用处理器微体系结构的优化，也就是处理器用来执行指令的底层系统设计。<br>​为了理解改进性能的方法，我们需要理解现代处理器的微体系结构。在实际的处理器中，是同时对多条指令求值，这个现象称为<strong>指令级并行</strong>。在某些设计中，可以有100条或更多条指令在处理中。采用一些精细的机制来确保这种并行执行的行为，正好能获得机器级程序要求的顺序语义模型的效果。</p><p>我们会发现两种 <strong>以CPE为单位（周期每元素）</strong> 的延迟界限描述了程序的最大性能。</p><ul><li>当一系列操作必须按照严格顺序执行时，就会遇到**延迟界限(latencybound)**，因为在下一条指令开始之前，这条指令必须结束。当代码中的数据相关限制了处理器利用指令级并行的能力时，延迟界限能够限定程序性能。</li><li>**吞吐量界限(throughput bound)**刻画了处理器功能单元的原始计算能力。这个界限是程序性能的终极限制</li></ul><h2 id="4-1-整体操作-乱序-超标量"><a href="#4-1-整体操作-乱序-超标量" class="headerlink" title="4.1 整体操作: 乱序 + 超标量"></a>4.1 整体操作: 乱序 + 超标量</h2><p>现代处理器一般是<strong>乱序</strong>且是<strong>超标量</strong>的。</p><ul><li><strong>超标量</strong>: 通过实现多个硬件单元，可以在每个时钟周期执行多个操作</li><li><strong>乱序</strong>: 指令执行的顺序和二进制代码中的顺序不一定相同</li></ul><p>架构如下图所示<br>      <img src="/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/e7832780740216a0dfbdcfea8e17c3ec.png" alt="中文版"></p><p>​</p><p><img src="/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/5-12.png" alt="英文版"></p><p>注意到，这种架构包含了两个单元</p><ul><li><p>指令控制单元</p><p>(ICU, Instruction Control Unit):</p><ul><li><p><strong>Fetch control</strong>: 包含分支预测的功能</p></li><li><p><strong>Instruction decode</strong>: 从icache中读取指令，然后翻译为一组微操作(x86)。例如，<code>addq %rax, %rdx</code>转换为单个微操作；<code>addq%rax, 8(%rdx)</code>转换为内存读取、加法和内存写入三个微操作。</p></li><li><p>Retirement Unit</p><p>: 退役单元控制寄存器文件，记录正在进行的处理并确保遵守顺序语义。指令译码时，和指令相关的信息入队，并一直保存在队列中，直到</p><ol><li>一条指令操作完成，且引起该指令运行的分支点也被认为预测正确，则该指令退役，对应的执行结果会更新寄存器</li><li>若某个分支点预测错误，则该指令会被flush，执行结果被丢弃</li></ol></li></ul></li><li><p>执行单元</p><p>(EU, Execution Unit): 接收来自ICU的微操作，分发到各个功能单元执行，每个时钟周期一般有多个操作。</p><ul><li><strong>Load和Store单元</strong>: 包含一个加法器计算地址，和dcache交互</li><li><strong>Branch单元</strong>: 预测会执行的指令执行结果会保存在EU内的队列中，若Branch单元计算发现预测错误，则会丢弃保存的执行结果，并通知<strong>Fetch Control</strong>单元，之后才能获取正确的指令</li><li><strong>其它各种功能单元</strong>: 通常一个算术运算单元能够执行多种运算，例如: 整数运算、浮点乘、整数乘、分支等等</li></ul></li></ul><p>注意: 为了避免分支预测错误，任何对程序寄存器的更新都只会在指令退役时发生。</p><p>为了加快传送某个单元操作结果到另一个单元的速度，执行单元之间也可以进行数据交换。一个常用技术被称为<strong>寄存器重命名</strong>。</p><ul><li>当条更新寄存器r的指令译码时，产生标记，得到一个指向该操作结果的唯一标识符。条目(r，t)被加入到一张表中，该表维护着每个程序寄存器r与会更新该寄存器的操作的标记t之间的关联。</li><li>当随后以寄存器r作为操作数的指令译码时，发送到执行单元的操作会包含t作为操作数源的值。当某个执行单元完成第一个操作时，会生成一个结果(v，t)，指明标记为t的操作产生值v。</li><li>所有等待t作为源的操作都能使用v作为源值，这就是一种形式的数据转发。</li></ul><p>通过这种机制，值可以直接从一个操作直接转发到另一个操作，就不需要先写入寄存器文件（<strong>隐含着需要分支判断正确，指令退役</strong>），之后再读出来。只要操作执行完成，无论预测失败与否，操作结果都可以转发并继续后续操作。注意: 该表只需维护写操作对应的寄存器，对于读操作，可以直接从寄存器文件获取这个操作数。</p><h2 id="4-2-功能单元的性能"><a href="#4-2-功能单元的性能" class="headerlink" title="4.2. 功能单元的性能"></a>4.2. 功能单元的性能</h2><p>Intel Core i7 Haswell CPU有下面8个功能单元:</p><ul><li>整数运算，浮点乘法，整数和浮点除法，分支</li><li>整数运算，浮点加法，整数乘，浮点乘</li><li>load，地址计算</li><li>load，地址计算</li><li>store</li><li>整数运算</li><li>整数运算，分支</li><li>store、store地址计算</li></ul><p>它们的性能参数分别如下</p><p><img src="/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/5-13.png"></p><ul><li><strong>latency</strong>: 完成运算需要的总时间</li><li><strong>issue</strong>: 两个连续同类型的运算的最小发射间隔时钟周期数</li><li><strong>capacity</strong>: 能够执行该功能单元的数量</li></ul><p>从以上性能参数我们能够分析得到下面这些结论</p><ul><li>乘法和加法的issue时间均为1，然而单个乘法操作以及浮点加法操作的latency均大于1，这是利用了流水线技术。issue时间为1的功能单元被称为<strong>完全流水线化（fully pipelined）</strong>。例如，浮点浮点加法的三个流水线级分别为<strong>处理指数</strong>，<strong>小数相加</strong>，<strong>结果舍入</strong>。</li><li>除法的latency和issue时间相同。这意味着每开始一次除法操作都需要首先完成上一次的除法操作。</li></ul><p><strong>功能单元的最大吞吐量</strong>: 对一个容量为C，发射时间为I的功能单元，它的最大吞吐量为C&#x2F;IC&#x2F;I。</p><p>对于不同的功能单元而言，它们的两个<strong>CPE界限（即单位是周期每元素）</strong>: 延迟界限（必须顺序执行时的CPE值）和吞吐量界限分别为:<br><img src="/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/5-14.png"> </p><h2 id="4-2处理器操作的抽象模型"><a href="#4-2处理器操作的抽象模型" class="headerlink" title="4.2处理器操作的抽象模型"></a>4.2处理器操作的抽象模型</h2><p>​我们会使用程序的**数据流(data-fow)<strong>表示，作为分析在现代处理器上执行的机器级程序性能的一个工具，这是一种图形化的表示方法，展现了不同操作之间的数据相关是如何限制它们的执行顺序的。这种限制形成了图中的</strong>关键路径(critical path)**，这是执行一组机器指令所需时钟周期数的一个下界。</p><p>​在继续技术细节之前，检査一下对函数combine4所获得的 CPE测量值是很有帮助的，到目前为止 combine4是最快的代码:</p><p><img src="/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/5-15.png"></p><p>注意到除了整数加法操作，其它操作的CPE值和延迟界限相同。事实上，此时整数加法中的<strong>数据相关</strong>构成了程序的关键路径。</p><p>可以通过数据流图研究这种相关性。对于内循环的汇编代码</p><figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs perl">.L25:<br> vmulsd (<span class="hljs-variable">%rdx</span>), <span class="hljs-variable">%xmm0</span>, <span class="hljs-variable">%xmm0</span>   <span class="hljs-comment"># multiply acc by data[i]</span><br> addq   <span class="hljs-variable">$8</span>, <span class="hljs-variable">%rdx</span>               <span class="hljs-comment"># increment data+i</span><br> cmpq   <span class="hljs-variable">%rax</span>, <span class="hljs-variable">%rdx</span>             <span class="hljs-comment"># %rdx - %rax</span><br> jne    .L25<br></code></pre></td></tr></table></figure><p>可以画出如下的数据流图</p><p><img src="/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/5-16.png"></p><p>注意到<code>vmulsd</code>指令被翻译成两个操作: load和mul。</p><p>循环中使用的寄存器能够被分成四类:</p><ul><li>只读:这些寄存器只用作源值，可以作为数据，也可以用来计算存储器地址，但是在循环中它们是不会被修改的。循环combine4的只读寄存器是rax和rbp。</li><li>只写:这些寄存器作为数据传送操作的目的。在本循环中没有这样的寄存器。</li><li>局部:这些寄存器在循环内部被修改和使用，迭代与迭代之间不相关。在这个循环中，条件码寄存器就是例子:cmp操作会修改它们，然后jg操作会使用它们，不过这种相关是在单次迭代之内的。</li><li>循环:对于循环来说，这些寄存器既作为源值，又作为目的，一次选代中产生的值会在另一次迭代中用到。可以看到，%rdx和xmm0是combine4的循环寄存器，对应于程序值i和acc。</li></ul><p>接下来可以看到，<strong>循环寄存器</strong>之间的操作链决定了限制性能的数据相关。</p><p>进一步对数据流图进行优化，消除不直接影响数据流的操作（即cmp和jne）以及循环寄存器后有：<br><img src="/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/5-17.png"><br>上图右侧的数据流表示的是单次迭代中进行的操作。当绘制多次迭代可以注意到<br><img src="/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/5-18.png"></p><p>注意到程序存在两条数据相关链:</p><ul><li>mul操作对%xmm0的修改</li><li>add操作对%rdx的修改</li></ul><p>在单精度浮点乘法条件下，由于mul操作的执行需要5个时钟周期，而数据依赖的情况下迭代n次就需要5n个时钟周期。加法操作需要1个时钟周期，因此n次迭代整体仅需要n个时钟周期。所以<strong>关键路径为mul操作的数据依赖</strong>。</p><p><strong>接下来我们希望提高重新调整操作的结构，增强指令级并行。具体而言，我们需要对程序做变换，使得唯一的限制因素是吞吐量界限</strong>。</p><h1 id="5-程序变换：循环展开"><a href="#5-程序变换：循环展开" class="headerlink" title="5.程序变换：循环展开"></a>5.程序变换：循环展开</h1><p><strong>循环展开</strong>: 通过增加一次迭代内的处理元素数，减少迭代次数。</p><ul><li><strong>减少循环开销</strong>: 减少不直接有助于得到程序结果的操作的数量，如条件判断</li><li><strong>缩短关键路径</strong>: 提供了减少关键路径上操作数量的方法</li></ul><p>修改后k&#x3D;2后的代码（每次进行操作k次）：2x1循环</p><p><img src="/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/98f982bce14c452f71c571fcf601884b.png"></p><p>对应获得的性能为：<br><img src="/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/5-20.png"></p><p><strong>注意到仍没有超过延迟界限，这是因为关键路径上仍有n个mul操作，仅是将循环开销减少了一半。</strong></p><h1 id="6-提高并行性"><a href="#6-提高并行性" class="headerlink" title="6. 提高并行性"></a>6. 提高并行性</h1><p>注意到，虽然程序性能受到运算单元的延迟限制，但是加法和乘法运算单元能够完全流水线化，然而循环展开并不能利用这种能力。<strong>本质原因在于我们使用单个累计变量，仅在该变量上一个值计算完成后，才能累积计算下一个值。</strong></p><h2 id="6-1-程序变换：提高并行性"><a href="#6-1-程序变换：提高并行性" class="headerlink" title="6.1 程序变换：提高并行性"></a>6.1 程序变换：提高并行性</h2><p>对于一个可交换且可结合的合并运算，我们可以将一组合并运算分割成两个或多个部分，并在最后合并结果以提高性能。</p><p>例如使用2x2循环展开的代码如下：<br>                    <img src="/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/b15da5717ca38d4c29177d86ad88585a.png"></p><p>此时可以做到两路并行乘法操作。对应的性能结果为：<br><img src="/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/5-23.png"></p><p>注意到几乎所有操作都改进了大约一倍。</p><p><img src="/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/5-24.png"></p><p>由于每个关键路径只包括1&#x2F;2个mul操作，因此CPE值减小为原来的1&#x2F;2。</p><p>考虑上述累计变量变换的一般形式，将循环展开为k次，同时并行使用k个循环变量。注意到当k&#x3D;10时，几乎能达到吞吐量界限。这是因为<strong>为了达到吞吐量界限，通常需要所有流水线都是满的，对延迟为L，容量为C的操作而言，就需要循环展开因子k &gt;&#x3D; L*C</strong>。</p><p>例如，浮点乘的L&#x3D;5，C&#x3D;2，则k需要大于等于10。而浮点加有L&#x3D;3，C&#x3D;1，因此k大于等于3就可以达到最大吞吐量。</p><h2 id="6-2-程序变换-重新结合变换"><a href="#6-2-程序变换-重新结合变换" class="headerlink" title="6.2. 程序变换: 重新结合变换"></a>6.2. 程序变换: 重新结合变换</h2><p>重新结合变换: 变换累积变量和向量元素的合并顺序。</p><p><img src="/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/bafa7e71320a3cdec1d53bb736ebca0e.png"><br>上面的变换被称为2x1a unrolling。步长为2，单个累积变量。</p><p>通过变换合并顺序，关键路径也减小了一半。</p><p>5-28说明了 combine7内循环的代码(对于单精度乘积的情况)是如何被译码成操作，以及得到的数据相关。我们看到，来自于movss和第一个mulss 指令的 load 操作从存储器中加载向量元素i和 i+1，第一个 mul操作把它们乘起来。然后，第二个mul操作把这个结果乘以累积值 acc。图 5-29 给出了我们如何对图 5-28的操作进行重新排列、优化和抽象，得到表示一次迭代中数据相关的模板(见图5-29b)。对于combine5和combine7的模板，有两个 1oad和两个 mu1 操作，但是只有一个mu1 操作形成了循环寄存器间的数据相关链。然后，把这个模板复制 n&#x2F;2次，给出了n个向量元素相乘所执行的计算(图5-30)，我们可以看到关键路径上只有n&#x2F;2 个操作。每次迭代内的第一个乘法都不需要等待前一次迭代的累积值就可以执行。因此,最小可能的 CPE减少了2倍。当我们增加k值时，每次迭代中关键路径上一直只有一个操作。</p><p><img src="/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/cb7603e5b8919c268d2a3f89713f78d4.png"><br>得到的性能如表所示：<br><img src="/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/5-28.png"></p><p>注意到和2x2 loop unrolling相比，2x1a计算的CPE大致相同，但是2x2 loop unrolling能够并行利用两个load单元。</p><p>注: <strong>由于浮点计算的不可结合性，编译器通常不会使用这些方式对浮点运算进行优化。</strong></p><h2 id="6-3-使用SIMD指令"><a href="#6-3-使用SIMD指令" class="headerlink" title="6.3. 使用SIMD指令"></a>6.3. 使用SIMD指令</h2><p>通过使用AVX指令，可以进一步提高并行性。</p><p><img src="/2024/08/26/CSAPP-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-5-%E4%BC%98%E5%8C%96/5-30.png"></p><h2 id="6-3-小结"><a href="#6-3-小结" class="headerlink" title="6.3. 小结"></a>6.3. 小结</h2><p>注意到，功能单元的吞吐量界限是一个极限下界。假设程序要执行n个操作，而硬件共有c个功能单元，且每个单元的发射时间为i，则程序至少需要（n&#x2F;c）∗i个时钟周期。</p><h1 id="7-性能优化的限制因素"><a href="#7-性能优化的限制因素" class="headerlink" title="7. 性能优化的限制因素"></a>7. 性能优化的限制因素</h1><ol><li><p>寄存器溢出</p><ul><li>循环并行性受汇编代码（通用寄存器资源）描述计算能力的限制。因此循环展开无法做到无限扩展，事实上之前的例子当从10x10扩展到20x20时，由于寄存器溢出，程序变量值会被存储在栈中，因而导致性能下降。</li></ul></li><li><p>分支预测与预测惩罚</p><ul><li><p>原则1:</p><p>不要过分关心可预测的分支。</p><ul><li>之前的示例中将每次迭代的元素获取从<code>get_vec_element()</code>中拿出来，然而性能基本没有变化，这说明<strong>分支在高度可预测的情况下，边界检查几乎不会影响性能</strong>。</li><li>注意: 这里说的是<strong>可预测的分支</strong>！！！对于难以预测的分支，性能还是会有大的变化。</li><li>分支预测失败，有大约20个周期的惩罚。</li></ul></li><li><p>原则2:</p><p>书写适合用条件传送实现的代码。</p><ul><li>使用条件传送替换传统的基于分支跳转的实现: 计算分支两个方向上的值，然后根据条件使用某一个方向上的值。</li></ul></li></ul></li></ol><p>GCC倾向于将如下<strong>函数式</strong>风格的代码转化为使用条件传送指令，该风格倾向于用条件操作来计算值，然后用值更新程序状态。相反，<strong>命令式</strong>风格倾向于根据条件语句有选择地更新程序状态。一个例子如下:</p><p><strong>命令式</strong></p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs arduino"><span class="hljs-comment">/*Rearrange two vectors so that for each i, bli]&gt;= a[i] */</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">minmax1</span><span class="hljs-params">(<span class="hljs-type">long</span> all, <span class="hljs-type">long</span> b[], <span class="hljs-type">long</span> n)</span></span>&#123;<br><span class="hljs-type">long</span> i;<br><span class="hljs-keyword">for</span>(i=<span class="hljs-number">0</span>;i&lt;n;i++) &#123;<br><span class="hljs-keyword">if</span>(a[i]&gt; b[i])&#123;<br><span class="hljs-type">long</span> t= ali];<br>a[i]= b[i];<br>b[i] = t;<br>&#125;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>函数式</strong></p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs arduino"><span class="hljs-comment">/*Rearrange two vectors so that for each i, bli]&gt;= a[i] */</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">minmax1</span><span class="hljs-params">(<span class="hljs-type">long</span> all, <span class="hljs-type">long</span> b[], <span class="hljs-type">long</span> n)</span></span>&#123;<br><span class="hljs-type">long</span> i;<br><span class="hljs-keyword">for</span>(i=<span class="hljs-number">0</span>;i&lt;n;i++) &#123;<br><span class="hljs-type">long</span> min = ali]&lt; b[i]? a[i] : b[i];<br><span class="hljs-type">long</span> max = ali]&lt; b[i] ? b[i] : a[i];<br>a[i]= min;<br>b[i]= max;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>CSAPP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CSAPP</tag>
      
      <tag>阅读笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
